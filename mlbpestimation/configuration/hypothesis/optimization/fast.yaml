defaults:
  - optimizer: adam
  - loss: meanabsoluteerror
  - _self_

optimizer:
  learning_rate: 1e-3
batch_size: 64
epoch: 1
n_batches: 10