defaults:
  - optimizer: adam
  - loss: meansquarederror
  - _self_

optimizer:
  learning_rate: 1e-3
batch_size: 64
epoch: 20
n_batches: 100
