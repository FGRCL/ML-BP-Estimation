{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from src.vitaldb.fetchingstrategy.VitalFileApi import VitalFileApi\n",
    "from src.vitaldb.casegenerator import VitalFileOptions\n",
    "from src.vitaldb.casesplit import split_generator\n",
    "from src.metrics.standardeviation import StandardDeviation, AbsoluteError\n",
    "import src.preprocessing.transforms as transforms\n",
    "import src.preprocessing.filters as filters\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.metrics import MeanAbsoluteError\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Create the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-29 16:33:05.571804: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "frequency = 500\n",
    "samples = range(1, 100)\n",
    "train_split = 0.7\n",
    "validate_split = 0.15\n",
    "validate_test = 0.15\n",
    "batching = False\n",
    "\n",
    "options = VitalFileOptions(\n",
    "    ['SNUADC/ART'],\n",
    "    1/frequency\n",
    ")\n",
    "\n",
    "train_generator, val_generator, test_generator = split_generator(options, VitalFileApi(), samples, [0.7, 0.15, 0.15])\n",
    "\n",
    "dataset_train = tf.data.Dataset.from_generator(\n",
    "    lambda: train_generator,\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None, 1), dtype=tf.float64)\n",
    "    )\n",
    ").take(1)\n",
    "\n",
    "dataset_val = tf.data.Dataset.from_generator(\n",
    "    lambda: val_generator,\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None, 1), dtype=tf.float64)\n",
    "    )\n",
    ").take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def abp_low_pass_graph_adapter(x, frequency):\n",
    "    return tf.numpy_function(transforms.abp_low_pass, [x, frequency], tf.float64)\n",
    "\n",
    "def extract_clean_windows_graph_adapter(x, frequency: int, window_size: int, step_size: int):\n",
    "    return tf.numpy_function(transforms.extract_clean_windows, [x, frequency, window_size, step_size], tf.float64)\n",
    "\n",
    "def preprocess_dataset(dataset: tf.data.Dataset):\n",
    "    dataset = dataset.filter(filters.has_data)\n",
    "    dataset = dataset.map(transforms.remove_nan)\n",
    "    dataset = dataset.map(lambda x: abp_low_pass_graph_adapter(x, frequency))\n",
    "    dataset = dataset.map(lambda x: extract_clean_windows_graph_adapter(x, frequency, 8, 2))\n",
    "    dataset= dataset.flat_map(transforms.to_tensor)\n",
    "    dataset = dataset.filter(lambda x: filters.pressure_out_of_bounds(x, 30, 230))\n",
    "    dataset = dataset.map(transforms.extract_sbp_dbp_from_abp_window)\n",
    "    dataset = dataset.map(transforms.scale_array)\n",
    "\n",
    "    if batching:\n",
    "        dataset = dataset.map(lambda d, l: (tf.reshape(d, shape=(4000, 1)), l))\n",
    "        dataset = dataset.batch(20).prefetch(2)\n",
    "    else:\n",
    "        dataset = dataset.map(lambda d, l: (tf.reshape(d, shape=(1, 4000)), l))\n",
    "\n",
    "    return dataset\n",
    "\n",
    "dataset_train = preprocess_dataset(dataset_train)\n",
    "dataset_val = preprocess_dataset(dataset_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CNN_LSTM\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 4000, 1)]         0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 3986, 64)          1024      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 3986, 64)         256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 996, 64)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 996, 64)           0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 996, 64)           33024     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 67,458\n",
      "Trainable params: 67,330\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (4000, 1)\n",
    "inputs = keras.Input(shape=input_shape)\n",
    "x = layers.Conv1D(64, 15, activation='relu', input_shape=(4000, 1))(inputs)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.MaxPooling1D(4)(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "x = layers.LSTM(64, return_sequences=True)(x)\n",
    "x = layers.LSTM(64)(x)\n",
    "outputs = layers.Dense(2)(x)\n",
    "\n",
    "model = keras.Model(inputs, outputs, name='CNN_LSTM')\n",
    "model.summary()\n",
    "model.compile(optimizer='Adam', loss=keras.losses.MeanAbsoluteError(),\n",
    "    metrics = [\n",
    "      MeanAbsoluteError(),\n",
    "      StandardDeviation(AbsoluteError())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francois/Library/Caches/pypoetry/virtualenvs/bpbaseline-d4rfio-H-py3.10/lib/python3.10/site-packages/scipy/interpolate/_fitpack2.py:280: UserWarning: \n",
      "The maximal number of iterations maxit (set to 20 by the program)\n",
      "allowed for finding a smoothing spline with fp=s has been reached: s\n",
      "too small.\n",
      "There is an approximation returned but the corresponding weighted sum\n",
      "of squared residuals does not satisfy the condition abs(fp-s)/s < tol.\n",
      "  warnings.warn(message)\n",
      "/Users/francois/Library/Caches/pypoetry/virtualenvs/bpbaseline-d4rfio-H-py3.10/lib/python3.10/site-packages/heartpy/analysis.py:778: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  measures['sd1/sd2'] = sd1 / sd2\n",
      "/Users/francois/Library/Caches/pypoetry/virtualenvs/bpbaseline-d4rfio-H-py3.10/lib/python3.10/site-packages/numpy/ma/core.py:5288: RuntimeWarning: Mean of empty slice.\n",
      "  result = super().mean(axis=axis, dtype=dtype, **kwargs)[()]\n",
      "/Users/francois/Library/Caches/pypoetry/virtualenvs/bpbaseline-d4rfio-H-py3.10/lib/python3.10/site-packages/numpy/core/_methods.py:182: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n",
      "/Users/francois/Library/Caches/pypoetry/virtualenvs/bpbaseline-d4rfio-H-py3.10/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3715: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/Users/francois/Library/Caches/pypoetry/virtualenvs/bpbaseline-d4rfio-H-py3.10/lib/python3.10/site-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/Users/francois/Library/Caches/pypoetry/virtualenvs/bpbaseline-d4rfio-H-py3.10/lib/python3.10/site-packages/numpy/core/_methods.py:257: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/francois/Library/Caches/pypoetry/virtualenvs/bpbaseline-d4rfio-H-py3.10/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/francois/Library/Caches/pypoetry/virtualenvs/bpbaseline-d4rfio-H-py3.10/lib/python3.10/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/francois/Library/Caches/pypoetry/virtualenvs/bpbaseline-d4rfio-H-py3.10/lib/python3.10/site-packages/numpy/core/_methods.py:265: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1599/1599 [==============================] - 488s 293ms/step - loss: 48.6980 - mean_absolute_error: 48.6980 - standard_deviation: 50.0455\n",
      "Epoch 2/10\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 15990 batches). You may need to use the repeat() function when building your dataset.\n",
      "1599/1599 [==============================] - 0s 210us/step - loss: 48.6980 - mean_absolute_error: 48.6980 - standard_deviation: 50.0455\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13c35d660>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"./logs\", histogram_freq = 1, profile_batch = '500,520')\n",
    "model.fit(dataset_train, epochs=10, callbacks=[tensorboard_callback], validation_data=dataset_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named ' tensorboard'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Input \u001B[0;32mIn [7]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mget_ipython\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_line_magic\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mload_ext\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m tensorboard\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m get_ipython()\u001B[38;5;241m.\u001B[39mrun_line_magic(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtensorboard\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m--logdir=logs\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/bpbaseline-d4rfio-H-py3.10/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2305\u001B[0m, in \u001B[0;36mInteractiveShell.run_line_magic\u001B[0;34m(self, magic_name, line, _stack_depth)\u001B[0m\n\u001B[1;32m   2303\u001B[0m     kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlocal_ns\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_local_scope(stack_depth)\n\u001B[1;32m   2304\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuiltin_trap:\n\u001B[0;32m-> 2305\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2306\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/bpbaseline-d4rfio-H-py3.10/lib/python3.10/site-packages/IPython/core/magics/extension.py:33\u001B[0m, in \u001B[0;36mExtensionMagics.load_ext\u001B[0;34m(self, module_str)\u001B[0m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m module_str:\n\u001B[1;32m     32\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m UsageError(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMissing module name.\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 33\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshell\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mextension_manager\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_extension\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodule_str\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     35\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m res \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124malready loaded\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m     36\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m extension is already loaded. To reload it, use:\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m module_str)\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/bpbaseline-d4rfio-H-py3.10/lib/python3.10/site-packages/IPython/core/extensions.py:76\u001B[0m, in \u001B[0;36mExtensionManager.load_extension\u001B[0;34m(self, module_str)\u001B[0m\n\u001B[1;32m     69\u001B[0m \u001B[38;5;124;03m\"\"\"Load an IPython extension by its module name.\u001B[39;00m\n\u001B[1;32m     70\u001B[0m \n\u001B[1;32m     71\u001B[0m \u001B[38;5;124;03mReturns the string \"already loaded\" if the extension is already loaded,\u001B[39;00m\n\u001B[1;32m     72\u001B[0m \u001B[38;5;124;03m\"no load function\" if the module doesn't have a load_ipython_extension\u001B[39;00m\n\u001B[1;32m     73\u001B[0m \u001B[38;5;124;03mfunction, or None if it succeeded.\u001B[39;00m\n\u001B[1;32m     74\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     75\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 76\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_load_extension\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodule_str\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     77\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mModuleNotFoundError\u001B[39;00m:\n\u001B[1;32m     78\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m module_str \u001B[38;5;129;01min\u001B[39;00m BUILTINS_EXTS:\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/bpbaseline-d4rfio-H-py3.10/lib/python3.10/site-packages/IPython/core/extensions.py:92\u001B[0m, in \u001B[0;36mExtensionManager._load_extension\u001B[0;34m(self, module_str)\u001B[0m\n\u001B[1;32m     90\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m module_str \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m sys\u001B[38;5;241m.\u001B[39mmodules:\n\u001B[1;32m     91\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m prepended_to_syspath(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mipython_extension_dir):\n\u001B[0;32m---> 92\u001B[0m         mod \u001B[38;5;241m=\u001B[39m \u001B[43mimport_module\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodule_str\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     93\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m mod\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__file__\u001B[39m\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mipython_extension_dir):\n\u001B[1;32m     94\u001B[0m             \u001B[38;5;28mprint\u001B[39m((\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLoading extensions from \u001B[39m\u001B[38;5;132;01m{dir}\u001B[39;00m\u001B[38;5;124m is deprecated. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     95\u001B[0m                    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWe recommend managing extensions like any \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     96\u001B[0m                    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mother Python packages, in site-packages.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m     97\u001B[0m                   \u001B[38;5;28mdir\u001B[39m\u001B[38;5;241m=\u001B[39mcompress_user(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mipython_extension_dir)))\n",
      "File \u001B[0;32m/usr/local/Cellar/python@3.10/3.10.4/Frameworks/Python.framework/Versions/3.10/lib/python3.10/importlib/__init__.py:126\u001B[0m, in \u001B[0;36mimport_module\u001B[0;34m(name, package)\u001B[0m\n\u001B[1;32m    124\u001B[0m             \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m    125\u001B[0m         level \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m--> 126\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_bootstrap\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_gcd_import\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m[\u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpackage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:1050\u001B[0m, in \u001B[0;36m_gcd_import\u001B[0;34m(name, package, level)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:1027\u001B[0m, in \u001B[0;36m_find_and_load\u001B[0;34m(name, import_)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:1004\u001B[0m, in \u001B[0;36m_find_and_load_unlocked\u001B[0;34m(name, import_)\u001B[0m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named ' tensorboard'"
     ]
    }
   ],
   "source": [
    "%load_ext  tensorboard\n",
    "%tensorboard --logdir=logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.save('models')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}