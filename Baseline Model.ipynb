{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Imports"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from src.vitaldb.fetchingstrategy.Sdk import Sdk\n",
    "from src.vitaldb.casegenerator import VitalFileOptions\n",
    "from src.vitaldb.casesplit import split_generator\n",
    "from src.metrics.standardeviation import StandardDeviation, AbsoluteError\n",
    "import src.preprocessing.transforms as transforms\n",
    "import src.preprocessing.filters as filters\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.metrics import MeanAbsoluteError\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create the datasets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-17 15:41:56.943448: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "frequency = 500\n",
    "samples = range(1, 100)\n",
    "train_split = 0.7\n",
    "validate_split = 0.15\n",
    "validate_test = 0.15\n",
    "batching = False\n",
    "\n",
    "options = VitalFileOptions(\n",
    "    ['SNUADC/ART'],\n",
    "    1/frequency\n",
    ")\n",
    "\n",
    "train_generator, val_generator, test_generator = split_generator(options, Sdk(), samples, [0.7, 0.15, 0.15])\n",
    "\n",
    "dataset_train = tf.data.Dataset.from_generator(\n",
    "    lambda: train_generator,\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None, 2), dtype=tf.float64)\n",
    "    )\n",
    ")\n",
    "\n",
    "dataset_val = tf.data.Dataset.from_generator(\n",
    "    lambda: val_generator,\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None, 2), dtype=tf.float64)\n",
    "    )\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Preprocess"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def abp_low_pass_graph_adapter(x, frequency):\n",
    "    return tf.numpy_function(transforms.abp_low_pass, [x, frequency], tf.float64)\n",
    "\n",
    "def extract_clean_windows_graph_adapter(x, frequency: int, window_size: int, step_size: int):\n",
    "    return tf.numpy_function(transforms.extract_clean_windows, [x, frequency, window_size, step_size], tf.float64)\n",
    "\n",
    "def preprocess_dataset(dataset: tf.data.Dataset):\n",
    "    dataset = dataset.filter(filters.has_data)\n",
    "    dataset = dataset.map(transforms.extract_abp_track)\n",
    "    dataset = dataset.map(transforms.remove_nan)\n",
    "    dataset = dataset.map(lambda x: abp_low_pass_graph_adapter(x, frequency))\n",
    "    dataset = dataset.map(lambda x: extract_clean_windows_graph_adapter(x, frequency, 8, 2))\n",
    "    dataset= dataset.flat_map(transforms.to_tensor)\n",
    "    dataset = dataset.filter(lambda x: filters.pressure_out_of_bounds(x, 30, 230))\n",
    "    dataset = dataset.map(transforms.extract_sbp_dbp_from_abp_window)\n",
    "    dataset = dataset.map(transforms.scale_array)\n",
    "\n",
    "    if batching:\n",
    "        dataset = dataset.map(lambda d, l: (tf.reshape(d, shape=(4000, 1)), l))\n",
    "        dataset = dataset.batch(20).prefetch(2)\n",
    "    else:\n",
    "        dataset = dataset.map(lambda d, l: (tf.reshape(d, shape=(1, 4000)), l))\n",
    "\n",
    "    return dataset\n",
    "\n",
    "dataset_train = preprocess_dataset(dataset_train).take(70)\n",
    "dataset_val = preprocess_dataset(dataset_val).take(15)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define the model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CNN_LSTM\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 4000, 1)]         0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 3986, 64)          1024      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 3986, 64)         256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 996, 64)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 996, 64)           0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 996, 64)           33024     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 67,458\n",
      "Trainable params: 67,330\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (4000, 1)\n",
    "inputs = keras.Input(shape=input_shape)\n",
    "x = layers.Conv1D(64, 15, activation='relu', input_shape=(4000, 1))(inputs)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.MaxPooling1D(4)(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "x = layers.LSTM(64, return_sequences=True)(x)\n",
    "x = layers.LSTM(64)(x)\n",
    "outputs = layers.Dense(2)(x)\n",
    "\n",
    "model = keras.Model(inputs, outputs, name='CNN_LSTM')\n",
    "model.summary()\n",
    "model.compile(optimizer='Adam', loss=keras.losses.MeanAbsoluteError(),\n",
    "    metrics = [\n",
    "      MeanAbsoluteError(),\n",
    "      StandardDeviation(AbsoluteError())\n",
    "    ]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "train the model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francois/Library/Caches/pypoetry/virtualenvs/bpbaseline-d4rfio-H-py3.10/lib/python3.10/site-packages/scipy/interpolate/_fitpack2.py:280: UserWarning: \n",
      "The maximal number of iterations maxit (set to 20 by the program)\n",
      "allowed for finding a smoothing spline with fp=s has been reached: s\n",
      "too small.\n",
      "There is an approximation returned but the corresponding weighted sum\n",
      "of squared residuals does not satisfy the condition abs(fp-s)/s < tol.\n",
      "  warnings.warn(message)\n",
      "/Users/francois/Library/Caches/pypoetry/virtualenvs/bpbaseline-d4rfio-H-py3.10/lib/python3.10/site-packages/heartpy/analysis.py:778: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  measures['sd1/sd2'] = sd1 / sd2\n",
      "/Users/francois/Library/Caches/pypoetry/virtualenvs/bpbaseline-d4rfio-H-py3.10/lib/python3.10/site-packages/numpy/ma/core.py:5246: RuntimeWarning: Mean of empty slice.\n",
      "  result = super().mean(axis=axis, dtype=dtype, **kwargs)[()]\n",
      "/Users/francois/Library/Caches/pypoetry/virtualenvs/bpbaseline-d4rfio-H-py3.10/lib/python3.10/site-packages/numpy/core/_methods.py:181: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = um.true_divide(\n",
      "/Users/francois/Library/Caches/pypoetry/virtualenvs/bpbaseline-d4rfio-H-py3.10/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3757: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/Users/francois/Library/Caches/pypoetry/virtualenvs/bpbaseline-d4rfio-H-py3.10/lib/python3.10/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/Users/francois/Library/Caches/pypoetry/virtualenvs/bpbaseline-d4rfio-H-py3.10/lib/python3.10/site-packages/numpy/core/_methods.py:256: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/francois/Library/Caches/pypoetry/virtualenvs/bpbaseline-d4rfio-H-py3.10/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/francois/Library/Caches/pypoetry/virtualenvs/bpbaseline-d4rfio-H-py3.10/lib/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/francois/Library/Caches/pypoetry/virtualenvs/bpbaseline-d4rfio-H-py3.10/lib/python3.10/site-packages/numpy/core/_methods.py:264: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/Users/francois/Library/Caches/pypoetry/virtualenvs/bpbaseline-d4rfio-H-py3.10/lib/python3.10/site-packages/numpy/core/_methods.py:222: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/Users/francois/Library/Caches/pypoetry/virtualenvs/bpbaseline-d4rfio-H-py3.10/lib/python3.10/site-packages/numpy/core/_methods.py:256: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/francois/Library/Caches/pypoetry/virtualenvs/bpbaseline-d4rfio-H-py3.10/lib/python3.10/site-packages/numpy/ma/core.py:5246: RuntimeWarning: Mean of empty slice.\n",
      "  result = super().mean(axis=axis, dtype=dtype, **kwargs)[()]\n",
      "/Users/francois/Library/Caches/pypoetry/virtualenvs/bpbaseline-d4rfio-H-py3.10/lib/python3.10/site-packages/numpy/core/_methods.py:181: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = um.true_divide(\n",
      "/Users/francois/Library/Caches/pypoetry/virtualenvs/bpbaseline-d4rfio-H-py3.10/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3757: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/Users/francois/Library/Caches/pypoetry/virtualenvs/bpbaseline-d4rfio-H-py3.10/lib/python3.10/site-packages/scipy/interpolate/_fitpack2.py:280: UserWarning: \n",
      "The maximal number of iterations maxit (set to 20 by the program)\n",
      "allowed for finding a smoothing spline with fp=s has been reached: s\n",
      "too small.\n",
      "There is an approximation returned but the corresponding weighted sum\n",
      "of squared residuals does not satisfy the condition abs(fp-s)/s < tol.\n",
      "  warnings.warn(message)\n",
      "/Users/francois/Library/Caches/pypoetry/virtualenvs/bpbaseline-d4rfio-H-py3.10/lib/python3.10/site-packages/scipy/interpolate/_fitpack2.py:280: UserWarning: \n",
      "The maximal number of iterations maxit (set to 20 by the program)\n",
      "allowed for finding a smoothing spline with fp=s has been reached: s\n",
      "too small.\n",
      "There is an approximation returned but the corresponding weighted sum\n",
      "of squared residuals does not satisfy the condition abs(fp-s)/s < tol.\n",
      "  warnings.warn(message)\n",
      "/Users/francois/Library/Caches/pypoetry/virtualenvs/bpbaseline-d4rfio-H-py3.10/lib/python3.10/site-packages/scipy/interpolate/_fitpack2.py:280: UserWarning: \n",
      "The maximal number of iterations maxit (set to 20 by the program)\n",
      "allowed for finding a smoothing spline with fp=s has been reached: s\n",
      "too small.\n",
      "There is an approximation returned but the corresponding weighted sum\n",
      "of squared residuals does not satisfy the condition abs(fp-s)/s < tol.\n",
      "  warnings.warn(message)\n",
      "/Users/francois/Library/Caches/pypoetry/virtualenvs/bpbaseline-d4rfio-H-py3.10/lib/python3.10/site-packages/scipy/interpolate/_fitpack2.py:280: UserWarning: \n",
      "The maximal number of iterations maxit (set to 20 by the program)\n",
      "allowed for finding a smoothing spline with fp=s has been reached: s\n",
      "too small.\n",
      "There is an approximation returned but the corresponding weighted sum\n",
      "of squared residuals does not satisfy the condition abs(fp-s)/s < tol.\n",
      "  warnings.warn(message)\n",
      "/Users/francois/Library/Caches/pypoetry/virtualenvs/bpbaseline-d4rfio-H-py3.10/lib/python3.10/site-packages/scipy/interpolate/_fitpack2.py:280: UserWarning: \n",
      "The maximal number of iterations maxit (set to 20 by the program)\n",
      "allowed for finding a smoothing spline with fp=s has been reached: s\n",
      "too small.\n",
      "There is an approximation returned but the corresponding weighted sum\n",
      "of squared residuals does not satisfy the condition abs(fp-s)/s < tol.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 46s 365ms/step - loss: 103.2723 - mean_absolute_error: 103.2723 - standard_deviation: 36.6929\n",
      "Epoch 2/10\n"
     ]
    }
   ],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"./logs\")\n",
    "model.fit(dataset_train, epochs=10, callbacks=[tensorboard_callback])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Evaluate the model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "metrics = model.evaluate(dataset_val,  callbacks=[tensorboard_callback])\n",
    "pd.DataFrame(metrics)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Save the model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.save('models')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}